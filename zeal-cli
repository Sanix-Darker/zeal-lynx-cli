#!/bin/python3

import argparse
import xdg
import sqlite3
import pathlib
from bs4 import BeautifulSoup
from subprocess import Popen, PIPE, STDOUT


# This script uses Zeal project's datasets to show
# the documentation pages in the awesome terminal
# web browser - lynx.
#
# -- Usage --
# To show a list of all available pages in a docset:
#
# zeal-cli DOCSET_NAME
#
# To show a particular page
#
# zeal-cli DOCSET_NAME PAGE
#
# By default, DOCSET_NAME is the name name of the directory
# where Zeal keeps a specific set of documentation files.
# For example, if the path to the installed documentation set
# is ~/.local/share/Zeal/Zeal/docsets/C++.docset/, the
# DOCSET_NAME will be "C++" (without the '.docset' extension)
#


# By changing docset_configuration, you can
# define a custom name for a docset. The following
# defines that 'cpp' will be an alias for the 'C++' docset,
# 'qt5' will be an alias for the 'Qt_5' docset, and 'qt6'
# will be an alias for the 'Qt_6' docset.
#
# As the documentation is often a siterip of official
# online docs, it can contain quite a few useless things like
# navigation menus, table of contents and other things
# that just take valuable space in lynx. You can define
# filters -- which tags to remove from the html before
# it is shown, and which tag to extract from the original
# html and show only its content ignoring the rest.

docset_configuration = {}
docset_configuration['cpp'] = {
    "zeal_name" : "C++",
    "to_remove" : [ "div.t-navbar", "table.toc" ],
    "to_show" : "div#bodyContent"
    }
docset_configuration['qt5'] = {
    "zeal_name" : "Qt_5",
    "to_show" : "div.context"
    }
docset_configuration['qt6'] = {
    "zeal_name" : "Qt_6",
    "to_show" : "div.context"
    }


# Start the code

parser = argparse.ArgumentParser(description='Zeal+Lynx.')
parser.add_argument('--zeal-prefix', help='Where are Zeal\'s files located?', nargs='?')
parser.add_argument('--lynx-dump', help='when "=true" -- dump rendered HTML to stdout instead of running Lynx proper', nargs='?')
parser.add_argument('docset', help='Which documentation set to use')
parser.add_argument('docpage', help='Which page to load', nargs='?')
args = parser.parse_args()

# Do we have a custom configuration for the current docset?
zeal_name = args.docset
current_docset_configuration = {}
try:
    current_docset_configuration = docset_configuration[args.docset]
    zeal_name = current_docset_configuration["zeal_name"]
except:
    pass

# If the user has Zeal files in a custom location,
# it can be specified with the --zeal-prefix flag
if args.zeal_prefix is None:
    args.zeal_prefix = xdg.xdg_data_home().joinpath('Zeal/Zeal').as_posix()

zeal_docset_prefix = args.zeal_prefix + "/docsets/" + zeal_name + ".docset/Contents/Resources"

db_url = pathlib.Path(zeal_docset_prefix + "/docSet.dsidx").as_uri()
db = sqlite3.connect(db_url + '?mode=ro', uri=True)

# A convenience function that allows the usual CSS syntax
# when specifying node filters -- div.class and div#id
def find_node(html, node_definition):
    class_sep_position = node_definition.find('.')
    if class_sep_position > -1:
        tag = node_definition[:class_sep_position]
        class_name = node_definition[class_sep_position + 1:]
        return html.find(tag, { "class" : class_name })

    else:
        id_sep_position = node_definition.find('#')
        tag = node_definition[:id_sep_position]
        id_name = node_definition[id_sep_position + 1:]
        return html.find(tag, { "id" : id_name })

if args.docpage is None:
    # No page was specified, we should list all the available pages
    for row in db.execute('SELECT name FROM searchIndex;'):
        print(row[0])
    pass

else:
    # extract the path to the page, and load it in lynx
    for row in db.execute('SELECT path FROM searchIndex WHERE name = :name;', { "name" : args.docpage }):
        relative_file_path = row[0]
        while relative_file_path[0] == '<':
            relative_file_path = relative_file_path[relative_file_path.find('>') + 1:]

        full_file_path = zeal_docset_prefix + "/Documents/" + relative_file_path
        file = open(full_file_path)
        html = BeautifulSoup(file, "html.parser")

        content = html
        try:
            for to_remove in current_docset_configuration["to_remove"]:
                find_node(html, to_remove).extract()
        except:
            pass

        try:
            content = find_node(html, current_docset_configuration["to_show"])
        except:
            pass

        if args.lynx_dump == "true":
            lynx_process = Popen(['lynx', '-stdin', '-dump'], stdin=PIPE)
        else:
            lynx_process = Popen(['lynx', '-stdin'], stdin=PIPE)

        stdout_data = lynx_process.communicate(input=str(content).encode('utf-8'))

    pass

